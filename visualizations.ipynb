{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./radiomicsFeaturesICC\"\n",
    "OUT_DIR = \"./figures\"\n",
    "AUG_TYPES = [\"in_plane_random\",\"in_plane_systematic\",\"out_plane\",\"inout_plane_random\",\"inout_plane_systematic\"]\n",
    "SOI = [\"t2w\",\"adc\",\"sub_win\",\"sub_wout\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FOLDER = \"plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for aug_type in AUG_TYPES:\n",
    "    \n",
    "    int_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_internal.csv\"), index_col=0).sort_values(by=[\"feat_family\",\"feature\", \"filter\"])\n",
    "    ext_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_external.csv\"), index_col=0).sort_values(by=[\"feat_family\",\"feature\", \"filter\"])\n",
    "    \n",
    "    int_df[\"full_feature\"] = int_df[\"feat_family\"]+\"_\"+int_df[\"feature\"]\n",
    "    int_df[\"stable\"] = (int_df[\"ci_down\"]>0.9).astype(int)\n",
    "    \n",
    "    ext_df[\"full_feature\"] = ext_df[\"feat_family\"]+\"_\"+ext_df[\"feature\"]\n",
    "    ext_df[\"stable\"] = (ext_df[\"ci_down\"]>0.9).astype(int)\n",
    "    \n",
    "    for sequence in SOI:\n",
    "        \n",
    "        out_path = os.path.join(OUT_DIR,OUT_FOLDER,sequence)\n",
    "        \n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "            \n",
    "        seq_df = {}\n",
    "\n",
    "        seq_df[\"internal\"] = int_df[int_df.sequence==sequence].reset_index(drop=True)\n",
    "        seq_df[\"external\"] = ext_df[ext_df.sequence==sequence.split(\"_\")[0]].reset_index(drop=True)\n",
    "     \n",
    "        idx = seq_df[\"internal\"].groupby([\"feat_family\",\"feature\"])[\"stable\"].transform(max)==seq_df[\"internal\"][\"stable\"]#will select the best filter; duplicates can exist\n",
    "\n",
    "        for ds_type in seq_df:\n",
    "            \n",
    "            uf_df = seq_df[ds_type][seq_df[ds_type][\"filter\"]==\"original\"]\n",
    "            bf_df = seq_df[ds_type][idx&(seq_df[ds_type][\"filter\"]!=\"original\")]\n",
    "            \n",
    "            merged_df = pd.concat([uf_df,bf_df])\n",
    "            \n",
    "            groups = [\"original\"] + sorted(bf_df[\"filter\"].unique()) #aligning the group original, filter1,filter2,etc\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "            for group in groups:\n",
    "\n",
    "                x = merged_df[merged_df[\"filter\"]==group].full_feature\n",
    "                y = merged_df[merged_df[\"filter\"]==group].icc_value\n",
    "\n",
    "                lower_ci = merged_df[merged_df[\"filter\"]==group].ci_down\n",
    "                upper_ci = merged_df[merged_df[\"filter\"]==group].ci_up\n",
    "\n",
    "                lower_error = y - lower_ci\n",
    "                upper_error = upper_ci - y\n",
    "\n",
    "                ax.errorbar(x, y, yerr=[lower_error, upper_error], fmt='o', capsize=4, label=group)\n",
    "\n",
    "                plt.fill_between(x, lower_ci, upper_ci, alpha=0.2)\n",
    "\n",
    "            ax.axhline(y=0.9, linestyle=\"--\",color='green')\n",
    "            ax.set_title('Original v/s Best Filtered Features')\n",
    "\n",
    "            ax.set_xlabel('Features')\n",
    "            ax.tick_params(axis='x', labelrotation=90, labelsize=10)\n",
    "\n",
    "            ax.set_ylabel('ICC Value')\n",
    "            ax.set_ylim([0,1])\n",
    "            ax.legend(title=\"Filters\",loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "            \n",
    "            plt.savefig(os.path.join(out_path,f\"{aug_type}_{ds_type}.png\"),bbox_inches = 'tight',\n",
    "                pad_inches = 0,dpi=300)\n",
    "\n",
    "            # close the figure to avoid memory leak\n",
    "            plt.close(fig)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap ICC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FOLDER = \"overlap_plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for aug_type in AUG_TYPES:\n",
    "    \n",
    "    int_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_internal.csv\"), index_col=0).sort_values(by=[\"feat_family\",\"feature\", \"filter\"])\n",
    "    ext_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_external.csv\"), index_col=0).sort_values(by=[\"feat_family\",\"feature\", \"filter\"])\n",
    "\n",
    "    int_df[\"full_feature\"] = int_df[\"feat_family\"]+\"_\"+int_df[\"feature\"]\n",
    "    int_df[\"stable\"] = (int_df[\"ci_down\"]>0.9).astype(int)\n",
    "    \n",
    "    ext_df[\"full_feature\"] = ext_df[\"feat_family\"]+\"_\"+ext_df[\"feature\"]\n",
    "    ext_df[\"stable\"] = (ext_df[\"ci_down\"]>0.9).astype(int)\n",
    "    \n",
    "    for sequence in SOI:\n",
    "        \n",
    "        out_path = os.path.join(OUT_DIR,OUT_FOLDER,sequence)\n",
    "        \n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "\n",
    "        seq_df = {}\n",
    "        \n",
    "        seq_df[\"internal\"] = int_df[int_df.sequence==sequence].reset_index(drop=True)\n",
    "        seq_df[\"external\"] = ext_df[ext_df.sequence==sequence.split(\"_\")[0]].reset_index(drop=True)\n",
    "        \n",
    "        uf_int = seq_df[\"internal\"][seq_df[\"internal\"][\"filter\"]==\"original\"]\n",
    "        uf_ext = seq_df[\"external\"][seq_df[\"external\"][\"filter\"]==\"original\"]\n",
    "        uf_overlap = pd.concat([uf_int,uf_ext]).groupby([\"feat_family\",\"feature\",\"filter\"]).min().reset_index()\n",
    "        \n",
    "        idx = seq_df[\"internal\"].groupby([\"feat_family\",\"feature\"])[\"stable\"].transform(max)==seq_df[\"internal\"][\"stable\"]#will select the best filter; duplicates can exist\n",
    "\n",
    "        bf_int = seq_df[\"internal\"][idx&(seq_df[\"internal\"][\"filter\"]!=\"original\")]\n",
    "        bf_ext = seq_df[\"external\"][idx&(seq_df[\"external\"][\"filter\"]!=\"original\")]\n",
    "        \n",
    "        bf_overlap = pd.concat([bf_int,bf_ext]).groupby([\"feat_family\",\"feature\",\"filter\"]).min().reset_index()\n",
    "       \n",
    "        idx = bf_overlap.groupby([\"feat_family\",\"feature\"])[\"ci_down\"].transform(max)==bf_overlap[\"ci_down\"]#will select the best filter; duplicates can exist\n",
    "        max_bf_overlap = bf_overlap[idx]\n",
    "        \n",
    "        \n",
    "        overlap_df = pd.concat([uf_overlap, max_bf_overlap])\n",
    "        groups = [\"original\"] + sorted(bf_overlap[\"filter\"].unique())\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "        for group in groups:\n",
    "\n",
    "            x = overlap_df[overlap_df[\"filter\"]==group].full_feature\n",
    "            y = overlap_df[overlap_df[\"filter\"]==group].icc_value\n",
    "\n",
    "            lower_ci = overlap_df[overlap_df[\"filter\"]==group].ci_down\n",
    "            upper_ci = overlap_df[overlap_df[\"filter\"]==group].ci_up\n",
    "\n",
    "            lower_error = y - lower_ci\n",
    "            upper_error = upper_ci - y\n",
    "\n",
    "            ax.errorbar(x, y, yerr=[lower_error, upper_error], fmt='o', capsize=4, label=group)\n",
    "\n",
    "            plt.fill_between(x, lower_ci, upper_ci, alpha=0.2)\n",
    "\n",
    "        ax.axhline(y=0.9, linestyle=\"--\",color='green')\n",
    "        ax.set_title('Original v/s Robust Filtered Features')\n",
    "\n",
    "        ax.set_xlabel('Features')\n",
    "        ax.tick_params(axis='x', labelrotation=90, labelsize=10)\n",
    "\n",
    "        ax.set_ylabel('ICC Value')\n",
    "        ax.set_ylim([0,1])\n",
    "        ax.legend(title=\"Filters\",loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "\n",
    "        plt.savefig(os.path.join(out_path,f\"{aug_type}.png\"),bbox_inches = 'tight',\n",
    "            pad_inches = 0,dpi=300)\n",
    "\n",
    "        # close the figure to avoid memory leak\n",
    "        plt.close(fig)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FOLDER = \"heatmaps\"\n",
    "\n",
    "ICC_THRESHOLD = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_DIM = (4,22)#4 feature family, 72 features in total; 22 is the maximum possibile number of members in a feature family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aug_type in AUG_TYPES:\n",
    "    \n",
    "    int_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_internal.csv\"), index_col=0).sort_values(by=[\"feat_family\",\"feature\", \"filter\"])\n",
    "    ext_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_external.csv\"), index_col=0).sort_values(by=[\"feat_family\",\"feature\", \"filter\"])\n",
    "    \n",
    "    int_df[\"full_feature\"] = int_df[\"feat_family\"]+\"_\"+int_df[\"feature\"]\n",
    "    int_df[\"stable\"] = (int_df[\"ci_down\"]>0.9).astype(int)\n",
    "    \n",
    "    ext_df[\"full_feature\"] = ext_df[\"feat_family\"]+\"_\"+ext_df[\"feature\"]\n",
    "    ext_df[\"stable\"] = (ext_df[\"ci_down\"]>0.9).astype(int)\n",
    "    \n",
    "    for sequence in SOI:\n",
    "        \n",
    "        out_path = os.path.join(OUT_DIR,OUT_FOLDER,sequence)\n",
    "        \n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "\n",
    "        seq_df = {}\n",
    "        seq_df[\"internal\"] = int_df[int_df.sequence==sequence].reset_index(drop=True)\n",
    "        seq_df[\"external\"] = ext_df[ext_df.sequence==sequence.split(\"_\")[0]].reset_index(drop=True)\n",
    "        \n",
    "        uf_int = seq_df[\"internal\"][seq_df[\"internal\"][\"filter\"]==\"original\"]\n",
    "        uf_ext = seq_df[\"external\"][seq_df[\"external\"][\"filter\"]==\"original\"]\n",
    "        uf_overlap = pd.concat([uf_int,uf_ext]).groupby([\"feat_family\",\"feature\",\"filter\"]).min().reset_index()\n",
    "    \n",
    "        idx = seq_df[\"internal\"].groupby([\"feat_family\",\"feature\"])[\"stable\"].transform(max)==seq_df[\"internal\"][\"stable\"]#will select the best filter; duplicates can exist\n",
    "\n",
    "        bf_int = seq_df[\"internal\"][idx&(seq_df[\"internal\"][\"filter\"]!=\"original\")].groupby([\"feat_family\",\"feature\"]).max().reset_index()\n",
    "        bf_ext = seq_df[\"external\"][idx&(seq_df[\"external\"][\"filter\"]!=\"original\")].groupby([\"feat_family\",\"feature\"]).max().reset_index()\n",
    "        bf_overlap = pd.concat([bf_int,bf_ext]).groupby([\"feat_family\",\"feature\",\"filter\"]).min().reset_index()\n",
    "        \n",
    "        map_dict = {\n",
    "            \"unfiltered\":{\"internal\":uf_int,\"external\":uf_ext, \"overlap\":uf_overlap},\n",
    "            \"filtered\":{\"internal\":bf_int, \"external\":bf_ext, \"overlap\":bf_overlap}\n",
    "        }\n",
    "        \n",
    "        fig, axes = plt.subplots(3,2, figsize = (15,10))\n",
    "        \n",
    "        #plt.show()\n",
    "        \n",
    "        for i,stat in enumerate(map_dict):\n",
    "            \n",
    "            for j,ds_type in enumerate(map_dict[stat]):\n",
    "                \n",
    "                axes[j,i].set_title(stat+\"_\"+ds_type)\n",
    "                \n",
    "                temp_df = map_dict[stat][ds_type].sort_values(by = [\"feat_family\",\"feature\"])\n",
    "                map_arr = np.ones(MAP_DIM) * -1\n",
    "                \n",
    "                feat_families = sorted(temp_df.feat_family.unique())\n",
    "                \n",
    "                for k,feat_family in enumerate(feat_families):\n",
    "                    \n",
    "                    arr = temp_df[temp_df.feat_family==feat_family].ci_down.to_numpy()\n",
    "                    map_arr[k,:len(arr)] = arr\n",
    "                \n",
    "                cmap_stable = sns.light_palette(\"seagreen\", as_cmap=True)\n",
    "                cmap_unstable = sns.dark_palette(\"gray\",as_cmap=True)\n",
    "                map_arr[map_arr>ICC_THRESHOLD] = 1\n",
    "                #annot_matrix = \n",
    "\n",
    "                sns.heatmap(map_arr, vmin=0, vmax=1, linewidths=2, mask=map_arr<1, cmap=cmap_stable, square=True, cbar=False, ax=axes[j,i])\n",
    "                sns.heatmap(map_arr, vmin=0, vmax=1, linewidths=2, mask=(map_arr==-1)|(map_arr==1), square=True, cmap=cmap_unstable, cbar=False, yticklabels=feat_families, ax=axes[j,i])\n",
    "               \n",
    "        #plt.subplots_adjust(hspace=0, wspace=0)\n",
    "        \n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_path,f\"{aug_type}.png\"),bbox_inches = 'tight',\n",
    "            pad_inches = 0,dpi=300)\n",
    "\n",
    "        # close the figure to avoid memory leak\n",
    "        plt.close(fig)\n",
    "  \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Plot for Filters & Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FOLDER = \"barplots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(OUT_DIR,OUT_FOLDER)\n",
    "    \n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "for aug_type in AUG_TYPES:\n",
    "\n",
    "    int_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_internal.csv\"), index_col=0).sort_values(by=[\"sequence\",\"feat_family\",\"feature\",\"filter\"])\n",
    "    int_df[\"stable\"] = (int_df[\"ci_down\"]>0.9).astype(int)\n",
    "    int_df[\"filter_family\"] = [i.split(\"-\")[0] for i in int_df[\"filter\"].values]\n",
    "\n",
    "\n",
    "    ext_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_external.csv\"), index_col=0).sort_values(by=[\"sequence\",\"feat_family\",\"feature\",\"filter\"])\n",
    "    ext_df[\"stable\"] = (ext_df[\"ci_down\"]>0.9).astype(int)\n",
    "    ext_df[\"filter_family\"] = [i.split(\"-\")[0] for i in ext_df[\"filter\"].values]\n",
    "    \n",
    "    idx = int_df.groupby([\"feat_family\",\"feature\"])[\"stable\"].transform(max)==int_df[\"stable\"]#will select the best filter; duplicates can exist\n",
    "    \n",
    "    ov_dfs = []\n",
    "    cols_to_keep = [\"sequence\",\"filter_family\",\"filter\",\"feature\",\"stable\"]\n",
    "    \n",
    "    for sequence in SOI:\n",
    "        \n",
    "        seq_int_df = int_df[int_df.sequence==sequence].sort_values(by=[\"feat_family\",\"feature\",\"filter\"]).reset_index(drop=True)\n",
    "        seq_ext_df = ext_df[ext_df.sequence==sequence.split(\"_\")[0]].sort_values(by=[\"feat_family\",\"feature\", \"filter\"]).reset_index(drop=True)\n",
    "        \n",
    "        idx = seq_int_df.groupby([\"feat_family\",\"feature\"])[\"stable\"].transform(max)==seq_int_df[\"stable\"]#will select the best filter; duplicates can exist\n",
    "    \n",
    "        \n",
    "        _int_df = seq_int_df[idx][cols_to_keep]\n",
    "        _ext_df = seq_ext_df[idx][cols_to_keep]\n",
    "        \n",
    "        bRobust = _int_df.stable&_ext_df.stable\n",
    "        \n",
    "        ov_df = _int_df.copy()\n",
    "        ov_df[\"robust\"] = bRobust.astype(int)\n",
    "        \n",
    "        ov_dfs.append(ov_df)\n",
    "        \n",
    "     \n",
    "    \n",
    "    ov_df = pd.concat(ov_dfs)\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n",
    "#     sns.catplot(data=ov_df, y=\"filter\", hue=\"robust\", kind=\"count\", ax=ax1)\n",
    "#     sns.catplot(data=ov_df, y=\"filter_family\", hue=\"robust\", kind=\"count\", ax=ax2)\n",
    "\n",
    "    filter_families = list(set(ov_df.filter_family)-{\"original\"})\n",
    "    sns.countplot(data=ov_df, y=\"filter_family\", hue=\"robust\", ax=ax1, order=[\"original\"]+sorted(filter_families))\n",
    "    filters = list(set(ov_df[\"filter\"])-{\"original\"})\n",
    "    sns.countplot(data=ov_df, y=\"filter\", hue=\"robust\", ax=ax2, order=[\"original\"] + sorted(filters))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_path,f\"{aug_type}.png\"),bbox_inches = 'tight',\n",
    "        pad_inches = 0,dpi=300)\n",
    "\n",
    "    # close the figure to avoid memory leak\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "    #idx = (_int_df.stable==1)&(_ext_df.stable==1)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table: Dice Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"./csv_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_DIR = r\"C:\\Users\\sithi\\Research\\INT-Projects\\stability\\radiomicsFeatures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FOLDER = \"dice_summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(OUT_DIR, OUT_FOLDER)\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "for ds_type in [\"internal\",\"external\"]:\n",
    "    out_df = {}\n",
    "    \n",
    "    for aug_type in AUG_TYPES:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(FEAT_DIR, f\"{aug_type}_{ds_type}.csv\"), index_col=0)\n",
    "        \n",
    "        sequences = df.sequence.unique()\n",
    "        \n",
    "        for sequence in sequences:\n",
    "        \n",
    "            out_df.setdefault((ds_type, sequence, \"mean\"),[]).append(df[df.sequence==sequence].dice.mean().round(2))\n",
    "            out_df.setdefault((ds_type, sequence, \"std\"),[]).append(df[df.sequence==sequence].dice.std().round(2))\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame(out_df,index=AUG_TYPES)\n",
    "    df.index.name = \"augmentation\"\n",
    "    \n",
    "    df.to_csv(os.path.join(out_path,f\"{ds_type}.csv\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table - Overall across all the augmentation scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICC_THRESHOLD = 0.90\n",
    "\n",
    "FEAT_FAMILIES = [\"firstorder\", \"glcm\", \"glrlm\", \"glszm\"]\n",
    "OUT_DIR = \"./csv_files\"\n",
    "OUT_FOLDER = \"overall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_dfs = []\n",
    "ext_dfs = []\n",
    "\n",
    "for aug_type in AUG_TYPES:\n",
    "\n",
    "    int_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_internal.csv\"), index_col=0)\n",
    "    int_df[\"aug_type\"] = [aug_type]*len(int_df)\n",
    "    int_df[\"stable\"] = (int_df[\"ci_down\"]>0.9).astype(int)\n",
    "    int_dfs.append(int_df)\n",
    "\n",
    "    ext_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_external.csv\"), index_col=0)\n",
    "    ext_df[\"aug_type\"] = [aug_type]*len(ext_df)\n",
    "    ext_df[\"stable\"] = (ext_df[\"ci_down\"]>0.9).astype(int)\n",
    "    ext_dfs.append(ext_df)\n",
    "\n",
    "merged_int_df = pd.concat(int_dfs).sort_values(by=[\"sequence\",\"aug_type\",\"feat_family\",\"feature\", \"filter\"]).reset_index(drop=True)\n",
    "merged_ext_df = pd.concat(ext_dfs).sort_values(by=[\"sequence\",\"aug_type\",\"feat_family\",\"feature\", \"filter\"]).reset_index(drop=True)\n",
    "\n",
    "out_path = os.path.join(OUT_DIR, OUT_FOLDER)\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "for sequence in SOI:\n",
    "    \n",
    "    index = []\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for aug_type in AUG_TYPES:\n",
    "\n",
    "        int_df = merged_int_df[(merged_int_df.sequence==sequence)&(merged_int_df.aug_type==aug_type)].drop([\"sequence\",\"aug_type\"], axis=1).reset_index(drop=True)\n",
    "        ext_df = merged_ext_df[(merged_ext_df.sequence==sequence.split(\"_\")[0])&(merged_ext_df.aug_type==aug_type)].drop([\"sequence\",\"aug_type\"], axis=1).reset_index(drop=True)\n",
    "      \n",
    "        uf_int = int_df[int_df[\"filter\"]==\"original\"].reset_index()\n",
    "        uf_ext = ext_df[ext_df[\"filter\"]==\"original\"].reset_index()\n",
    "        \n",
    "        uf_overlap = pd.concat([uf_int,uf_ext]).groupby([\"feat_family\",\"feature\",\"filter\"]).min().reset_index()\n",
    "        \n",
    "        idx = int_df.groupby([\"feat_family\",\"feature\"])[\"stable\"].transform(max)==int_df[\"stable\"]#best filters(s) or non_filter for each feature\n",
    "\n",
    "        \n",
    "        bf_int = int_df[idx&int_df[\"filter\"]!=\"original\"]\n",
    "        bf_ext = ext_df[idx&ext_df[\"filter\"]!=\"original\"]\n",
    "        bf_overlap = pd.concat([bf_int,bf_ext]).groupby([\"feat_family\",\"feature\",\"filter\"]).min().reset_index()\n",
    "        \n",
    "        #idx = bf_overlap.groupby([\"feat_family\",\"feature\"])[\"ci_down\"].transform(max)==bf_overlap[\"ci_down\"]#will select the best filter; duplicates can exist\n",
    "        max_bf_overlap = bf_overlap.groupby([\"feat_family\",\"feature\"]).max().reset_index()\n",
    "        max_bf_int = bf_int.groupby([\"feat_family\",\"feature\"]).max().reset_index()\n",
    "        \n",
    "        total_feats = 0\n",
    "        \n",
    "        row = {}\n",
    "        \n",
    "        column_order = []\n",
    "        \n",
    "        \n",
    "        for feat_family in FEAT_FAMILIES:\n",
    "            \n",
    "            \n",
    "            num_feats = len(uf_int[uf_int.feat_family==feat_family])\n",
    "            \n",
    "            o_stable = uf_int[uf_int.feat_family==feat_family].stable.sum()\n",
    "            o_robust = uf_overlap[uf_overlap.feat_family==feat_family].stable.sum()#sum((uf_int_df[uf_int_df.feat_family==feat_family].stable)*(uf_ext_df[uf_ext_df.feat_family==feat_family].stable))\n",
    "            \n",
    "        \n",
    "            \n",
    "            bf_stable = max_bf_int[max_bf_int.feat_family==feat_family].stable.sum()\n",
    "            bf_robust = max_bf_overlap[max_bf_overlap.feat_family==feat_family].stable.sum()#sum((bf_int_df[bf_int_df.feat_family==feat_family].stable==1)&(bf_ext_df[bf_ext_df.feat_family==feat_family].stable==1))\n",
    "            \n",
    "            \n",
    "            row[(sequence, feat_family,\"O\", \"S\")] = [np.round(o_stable/num_feats,2)]\n",
    "            row[(sequence, feat_family,\"O\", \"R\")] = [np.round(o_robust/num_feats,2)]\n",
    "            \n",
    "            row[(sequence, feat_family,\"BF\", \"S\")] = [np.round(bf_stable/num_feats,2)]\n",
    "            row[(sequence, feat_family, \"BF\", \"R\")] = [np.round(bf_robust/num_feats,2)]\n",
    "            \n",
    "            row.setdefault((sequence, \"Overall\", \"O\",\"S\"),[]).append(o_stable)\n",
    "            row.setdefault((sequence, \"Overall\", \"O\",\"R\"),[]).append(o_robust)\n",
    "            row.setdefault((sequence, \"Overall\", \"BF\",\"S\"),[]).append(bf_stable)\n",
    "            row.setdefault((sequence, \"Overall\", \"BF\",\"R\"),[]).append(bf_robust)\n",
    "            \n",
    "            column_order = [(i,feat_family,j,k) for i,feat_family,j,k in row.keys() if feat_family in FEAT_FAMILIES]\n",
    "            \n",
    "            total_feats += num_feats\n",
    "        \n",
    "            \n",
    "        row[(sequence, \"Overall\", \"O\",\"S\")] = np.round(sum(row[(sequence, \"Overall\", \"O\",\"S\")])/total_feats,2)\n",
    "        row[(sequence, \"Overall\", \"O\",\"R\")] = np.round(sum(row[(sequence, \"Overall\", \"O\",\"R\")])/total_feats,2)\n",
    "        row[(sequence, \"Overall\", \"BF\",\"S\")] = np.round(sum(row[(sequence, \"Overall\", \"BF\",\"S\")])/total_feats,2)\n",
    "        row[(sequence, \"Overall\", \"BF\",\"R\")] = np.round(sum(row[(sequence, \"Overall\", \"BF\",\"R\")])/total_feats,2)\n",
    "        \n",
    "        columns = row.keys()\n",
    "        column_order = [key for key in columns if \"Overall\" not in str(key)] + [key for key in columns if \"Overall\" in str(key)]\n",
    "        \n",
    "        dfs.append(pd.DataFrame(row,index=[aug_type]))\n",
    "        \n",
    "    out_df = pd.concat(dfs)\n",
    "    out_df = out_df.reindex(columns=column_order)\n",
    "    \n",
    "    out_df.index.name = \"augmentation\"\n",
    "    out_df.to_csv(os.path.join(out_path,f\"{sequence}.csv\"))\n",
    "    \n",
    "    #display(out_df)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table - Extracted Feature Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_FOLDER = \"feats_overview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(OUT_DIR, OUT_FOLDER)\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, f\"inout_plane_systematic_internal.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = df.groupby([\"feat_family\",\"feature\"])[\"filter\"].apply(set).reset_index()\n",
    "out_df[\"filter\"] = out_df[\"filter\"].apply(lambda x:sorted(x))\n",
    "pd.DataFrame(out_df).to_csv(os.path.join(out_path,f\"output.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table - Robust Features for each sequence, Export as excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICC_THRESHOLD = 0.90\n",
    "OUT_DIR = \"./csv_files\"\n",
    "\n",
    "OUT_FOLDER = \"robust_feats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(OUT_DIR, OUT_FOLDER)\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)\n",
    "\n",
    "for aug_type in AUG_TYPES:\n",
    "    \n",
    "    int_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_internal.csv\"), index_col=0).sort_values(by=[\"feat_family\",\"feature\", \"filter\"])\n",
    "    ext_df = pd.read_csv(os.path.join(DATA_DIR, f\"{aug_type}_external.csv\"), index_col=0).sort_values(by=[\"feat_family\",\"feature\", \"filter\"])\n",
    "\n",
    "    int_df[\"full_feature\"] = int_df[\"feat_family\"]+\"_\"+int_df[\"feature\"]\n",
    "    int_df[\"stable\"] = (int_df[\"ci_down\"]>0.9).astype(int)\n",
    "    \n",
    "    ext_df[\"full_feature\"] = ext_df[\"feat_family\"]+\"_\"+ext_df[\"feature\"]\n",
    "    ext_df[\"stable\"] = (ext_df[\"ci_down\"]>0.9).astype(int)\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for sequence in SOI:\n",
    "        \n",
    "        seq_df = {}\n",
    "        \n",
    "        seq_df[\"internal\"] = int_df[int_df.sequence==sequence].reset_index(drop=True)\n",
    "        seq_df[\"external\"] = ext_df[ext_df.sequence==sequence.split(\"_\")[0]].reset_index(drop=True)\n",
    "        \n",
    "        uf_int = seq_df[\"internal\"][seq_df[\"internal\"][\"filter\"]==\"original\"]\n",
    "        uf_ext = seq_df[\"external\"][seq_df[\"external\"][\"filter\"]==\"original\"]\n",
    "        uf_overlap = pd.concat([uf_int,uf_ext]).groupby([\"feat_family\",\"feature\",\"filter\"]).min().reset_index()\n",
    "        \n",
    "        idx = seq_df[\"internal\"].groupby([\"feat_family\",\"feature\"])[\"stable\"].transform(max)==seq_df[\"internal\"][\"stable\"]#will select the best filter; duplicates can exist\n",
    "\n",
    "        bf_int = seq_df[\"internal\"][idx&(seq_df[\"internal\"][\"filter\"]!=\"original\")]\n",
    "        bf_ext = seq_df[\"external\"][idx&(seq_df[\"external\"][\"filter\"]!=\"original\")]\n",
    "        \n",
    "        bf_overlap = pd.concat([bf_int,bf_ext]).groupby([\"feat_family\",\"feature\",\"filter\"]).min().reset_index()\n",
    "        cf_overlap = pd.concat([bf_overlap, uf_overlap])\n",
    "    \n",
    "        \n",
    "        out_df = pd.DataFrame(cf_overlap[cf_overlap.stable==1].groupby([\"sequence\",\"feat_family\",\"feature\"])[\"filter\"].apply(set)).reset_index()\n",
    "        out_df[\"filter\"] = out_df[\"filter\"].apply(lambda x:sorted(x))\n",
    "        dfs.append(out_df)\n",
    "\n",
    "        \n",
    "    out_df = pd.concat(dfs)\n",
    "    out_df.to_csv(os.path.join(out_path,f\"{aug_type}.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Generate some sample data\n",
    "# x = np.array([1, 2, 3, 4, 5])\n",
    "# y = np.array([1.2, 2.3, 3.5, 4.1, 5.2])\n",
    "# lower_error = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "# upper_error = np.array([0.2, 0.3, 0.4, 0.1, 0.5])\n",
    "\n",
    "# # Calculate the confidence intervals\n",
    "# lower_ci = y - lower_error\n",
    "# upper_ci = y + upper_error\n",
    "\n",
    "# # Plot the error bars\n",
    "# plt.errorbar(x, y, yerr=[lower_error, upper_error], fmt='o', capsize=4)\n",
    "\n",
    "# # Plot the confidence intervals\n",
    "# plt.fill_between(x, lower_ci, upper_ci, alpha=0.2)\n",
    "\n",
    "# # Set the plot title and axis labels\n",
    "# plt.title('Error Bar Plot with Confidence Intervals')\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Generate some example data\n",
    "# np.random.seed(1)\n",
    "# x = np.arange(0, 10, 1)\n",
    "# y1 = np.random.normal(loc=0, scale=1, size=10)\n",
    "# y2 = np.random.normal(loc=2, scale=1, size=10)\n",
    "# y3 = np.random.normal(loc=4, scale=1, size=10)\n",
    "# y_err1 = np.random.normal(loc=0, scale=0.5, size=10)\n",
    "# y_err2 = np.random.normal(loc=0, scale=0.5, size=10)\n",
    "# y_err3 = np.random.normal(loc=0, scale=0.5, size=10)\n",
    "\n",
    "# # Create a line plot with error bars for each group\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.errorbar(x, y1, yerr=y_err1, fmt='-o', label='Group 1')\n",
    "# ax.errorbar(x, y2, yerr=y_err2, fmt='-o', label='Group 2')\n",
    "# ax.errorbar(x, y3, yerr=y_err3, fmt='-o', label='Group 3')\n",
    "# ax.set_xlabel('X-axis label')\n",
    "# ax.set_ylabel('Y-axis label')\n",
    "# ax.set_title('Line plot with error bars for multiple groups')\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Generate some example data\n",
    "# np.random.seed(1)\n",
    "# x = np.arange(0, 10, 1)\n",
    "# y1 = np.random.normal(loc=0, scale=1, size=10)\n",
    "# y2 = np.random.normal(loc=2, scale=1, size=10)\n",
    "# y3 = np.random.normal(loc=4, scale=1, size=10)\n",
    "# y_err1 = np.random.normal(loc=0, scale=0.5, size=10)\n",
    "# y_err2 = np.random.normal(loc=0, scale=0.5, size=10)\n",
    "# y_err3 = np.random.normal(loc=0, scale=0.5, size=10)\n",
    "\n",
    "# # Create a stacked line plot with confidence intervals and different markers\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y1, marker='o', label='Group 1')\n",
    "# ax.fill_between(x, y1-y_err1, y1+y_err1, alpha=0.2)\n",
    "# ax.plot(x, y2, marker='s', label='Group 2')\n",
    "# ax.fill_between(x, y2-y_err2, y2+y_err2, alpha=0.2)\n",
    "# ax.plot(x, y3, marker='^', label='Group 3')\n",
    "# ax.fill_between(x, y3-y_err3, y3+y_err3, alpha=0.2)\n",
    "# ax.set_xlabel('X-axis label')\n",
    "# ax.set_ylabel('Y-axis label')\n",
    "# ax.set_title('Stacked line plot with confidence intervals and different markers')\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups = max_seq_df[\"filter\"].unique()\n",
    "\n",
    "# # Plot the error bars\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 12))\n",
    "\n",
    "# for group in groups:\n",
    "    \n",
    "#     x = max_seq_df[max_seq_df[\"filter\"]==group].icc_value\n",
    "#     y = max_seq_df[max_seq_df[\"filter\"]==group].full_feature\n",
    "    \n",
    "#     lower_ci = max_seq_df[max_seq_df[\"filter\"]==group].ci_down\n",
    "#     upper_ci = max_seq_df[max_seq_df[\"filter\"]==group].ci_up\n",
    "    \n",
    "#     lower_error = x - lower_ci\n",
    "#     upper_error = upper_ci - x\n",
    "    \n",
    "#     fmt = 'o' if group==\"original\" else '^'\n",
    "#     ax.errorbar(x, y, xerr=[lower_error, upper_error], fmt=fmt, capsize=4, label=group)\n",
    "#     #ax.errorbar(x, y, yerr=[lower_error, upper_error], fmt='o', capsize=4, label=group)\n",
    "\n",
    "#     #Plot the confidence intervals\n",
    "    \n",
    "#     #if group==\"original\":\n",
    "#     #plt.fill_between(y, lower_ci, upper_ci, alpha=0.2)\n",
    "    \n",
    "# ax.set_xlabel('ICC Value')\n",
    "# ax.set_ylabel('ICC Value')\n",
    "# ax.set_title('Line plot with error bars for multiple groups')\n",
    "# ax.legend()\n",
    "\n",
    "# # # Set the plot title and axis labels\n",
    "# # plt.title('Error Bar Plot with Confidence Intervals')\n",
    "# # plt.xlabel('X')\n",
    "# # plt.ylabel('Y')\n",
    "\n",
    "# # Show the plot\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Generate some sample data\n",
    "# x = np.array([\"f1\", \"f2\", \"f3\", \"f4\", \"f5\"])\n",
    "# y1 = np.array([0.83, 0.93, 0.93, 0.89, 1.0])\n",
    "# y2 = np.array([0.83, 0.92, 0.94, 0.90, 0.9])\n",
    "\n",
    "# lower_ci = np.array([0.83, 0.90, 0.93, 0.84, 0.95])\n",
    "# upper_ci = np.array([0.89, 0.95, 0.94, 0.91, 1.0])\n",
    "\n",
    "# lower_error = y1 - lower_ci\n",
    "# upper_error = upper_ci - y1\n",
    "\n",
    "\n",
    "# # # Calculate the confidence intervals\n",
    "# # lower_ci = y - lower_error\n",
    "# # upper_ci = y + upper_error\n",
    "\n",
    "# # Plot the error bars\n",
    "# plt.errorbar(x, y1, yerr=[lower_error, upper_error], fmt='o', capsize=4, label=\"Group 1\")\n",
    "\n",
    "# #Plot the confidence intervals\n",
    "# plt.fill_between(x, lower_ci, upper_ci, alpha=0.2)\n",
    "\n",
    "# # Set the plot title and axis labels\n",
    "# plt.title('Error Bar Plot with Confidence Intervals')\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Generate some sample data\n",
    "# x = np.array(['A', 'B', 'C', 'D', 'E'])\n",
    "# y = np.array([1.2, 2.3, 3.5, 4.1, 5.2])\n",
    "# lower_ci = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "# upper_ci = np.array([0.2, 0.3, 0.4, 0.1, 0.5])\n",
    "\n",
    "# # Set the figure size and font style\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "# plt.rcParams['font.size'] = 12\n",
    "\n",
    "# # Plot the error bars\n",
    "# plt.errorbar(x, y, yerr=[lower_ci, upper_ci], fmt='o', capsize=4,\n",
    "#              color='black', ecolor='gray', elinewidth=1, capthick=1)\n",
    "\n",
    "# # Set the plot title and axis labels\n",
    "# plt.title('Error Bars with Categorical X-Axis')\n",
    "# plt.xlabel('Category')\n",
    "# plt.ylabel('Value')\n",
    "\n",
    "# # Adjust the plot limits and ticks\n",
    "# plt.ylim([np.min(y) - 0.5, np.max(y) + 0.5])\n",
    "# plt.yticks(np.arange(np.min(y), np.max(y) + 0.5, 0.5))\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
